import whisper
import pandas as pd
import re
from typing import List, Dict

def load_vocabulary_from_csv(csv_path: str) -> tuple:
    """
    Äá»c file label.csv vÃ  tráº£ vá» danh sÃ¡ch tá»« vá»±ng + tá»« Ä‘iá»ƒn Ä‘á»“ng nghÄ©a
    """
    try:
        df = pd.read_csv(csv_path)
        
        # Táº¡o tá»« Ä‘iá»ƒn: tá»« gá»‘c -> danh sÃ¡ch tá»« Ä‘á»“ng nghÄ©a
        synonym_dict = {}
        # Táº¡o tá»« Ä‘iá»ƒn ngÆ°á»£c: tá»« Ä‘á»“ng nghÄ©a -> tá»« gá»‘c
        reverse_synonym_dict = {}
        
        for _, row in df.iterrows():
            label = row['LABEL']
            synonyms_str = row.get('SYNONYMS', '')
            
            if pd.notna(synonyms_str) and synonyms_str.strip():
                # TÃ¡ch cÃ¡c tá»« Ä‘á»“ng nghÄ©a (cÃ¡ch nhau bá»Ÿi dáº¥u pháº©y)
                synonyms = [s.strip() for s in synonyms_str.split(',') if s.strip()]
                synonym_dict[label] = synonyms
                
                # Táº¡o mapping ngÆ°á»£c
                for synonym in synonyms:
                    if synonym not in reverse_synonym_dict:
                        reverse_synonym_dict[synonym] = []
                    reverse_synonym_dict[synonym].append(label)
        
        # Láº¥y danh sÃ¡ch tá»« vá»±ng gá»‘c
        vocabulary = df['LABEL'].dropna().unique().tolist()
        
        print(f"âœ… ÄÃ£ táº£i {len(vocabulary)} tá»« vá»±ng tá»« file CSV")
        print(f"ğŸ“š CÃ³ {len(synonym_dict)} tá»« vá»±ng cÃ³ tá»« Ä‘á»“ng nghÄ©a")
        print(f"ğŸ”„ Tá»•ng {sum(len(syns) for syns in synonym_dict.values())} tá»« Ä‘á»“ng nghÄ©a")
        
        return vocabulary, synonym_dict, reverse_synonym_dict
        
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c file CSV: {e}")
        return [], {}, {}

def is_valid_match(vocab_word: str, segment_text: str) -> bool:
    """
    Kiá»ƒm tra xem tá»« vá»±ng cÃ³ phÃ¹ há»£p vá»›i ngá»¯ cáº£nh khÃ´ng
    """
    vocab_lower = vocab_word.lower().strip()
    text_lower = segment_text.lower()
    
    # TÃ¬m vá»‹ trÃ­ cá»§a tá»« vá»±ng trong text
    pattern = r'\b' + re.escape(vocab_lower) + r'\b'
    match = re.search(pattern, text_lower)
    
    if not match:
        return False
    
    start_pos = match.start()
    end_pos = match.end()
    
    # Kiá»ƒm tra kÃ½ tá»± trÆ°á»›c vÃ  sau tá»« vá»±ng
    char_before = text_lower[start_pos - 1] if start_pos > 0 else ' '
    char_after = text_lower[end_pos] if end_pos < len(text_lower) else ' '
    
    # Loáº¡i bá» náº¿u tá»« vá»±ng lÃ  má»™t pháº§n cá»§a tá»« ghÃ©p
    # VÃ­ dá»¥: "háº¥p" trong "háº¥p dáº«n" sáº½ bá»‹ loáº¡i
    if char_after.isalpha() and not char_after.isspace():
        return False
    
    # Kiá»ƒm tra má»™t sá»‘ trÆ°á»ng há»£p Ä‘áº·c biá»‡t
    common_compounds = {
        'háº¥p': ['háº¥p dáº«n', 'háº¥p thá»¥'],
        'dáº«n': ['háº¥p dáº«n', 'dáº«n Ä‘áº§u', 'dáº«n dáº¯t'],
        'tham': ['tham gia', 'tham kháº£o', 'tham quan'],
        'gia': ['tham gia', 'gia Ä‘Ã¬nh', 'gia tÄƒng'],
        'kháº£o': ['tham kháº£o', 'kháº£o sÃ¡t'],
        'quan': ['tham quan', 'quan tÃ¢m', 'quan trá»ng'],
        'tÃ¢m': ['quan tÃ¢m', 'tÃ¢m lÃ½', 'trung tÃ¢m'],
        'trá»ng': ['quan trá»ng', 'trá»ng lÆ°á»£ng'],
        'lÃ½': ['tÃ¢m lÃ½', 'lÃ½ do', 'xá»­ lÃ½'],
        'xá»­': ['xá»­ lÃ½', 'xá»­ pháº¡t'],
        'pháº¡t': ['xá»­ pháº¡t', 'pháº¡t tiá»n']
    }
    
    if vocab_lower in common_compounds:
        # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  má»™t pháº§n cá»§a tá»« ghÃ©p khÃ´ng
        for compound in common_compounds[vocab_lower]:
            if compound in text_lower and compound != vocab_lower:
                return False
    
    return True

def find_vocabulary_in_text(transcription_result: Dict, vocabulary_list: List[str], synonym_dict: Dict, reverse_synonym_dict: Dict) -> List[Dict]:
    """
    TÃ¬m cÃ¡c tá»« vá»±ng tá»« danh sÃ¡ch trong text Ä‘Ã£ transcribe vá»›i kiá»ƒm tra ngá»¯ cáº£nh vÃ  tá»« Ä‘á»“ng nghÄ©a
    """
    found_words = []
    segments = transcription_result.get('segments', [])
    
    # Sáº¯p xáº¿p tá»« vá»±ng theo Ä‘á»™ dÃ i giáº£m dáº§n Ä‘á»ƒ Æ°u tiÃªn tá»« ghÃ©p
    vocabulary_sorted = sorted(vocabulary_list, key=len, reverse=True)
    
    for segment in segments:
        segment_text = segment['text'].strip()
        segment_start = segment['start']
        segment_end = segment['end']
        text_lower = segment_text.lower()
        
        # Theo dÃµi cÃ¡c vá»‹ trÃ­ Ä‘Ã£ Ä‘Æ°á»£c match Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
        matched_positions = []
        
        # 1. TÃ¬m tá»« vá»±ng gá»‘c trá»±c tiáº¿p
        for vocab_word in vocabulary_sorted:
            vocab_lower = vocab_word.lower().strip()
            
            pattern = r'\b' + re.escape(vocab_lower) + r'\b'
            matches = list(re.finditer(pattern, text_lower))
            
            for match in matches:
                start_pos = match.start()
                end_pos = match.end()
                
                position_taken = any(
                    start_pos < existing_end and end_pos > existing_start
                    for existing_start, existing_end in matched_positions
                )
                
                if not position_taken and is_valid_match(vocab_word, segment_text):
                    found_words.append({
                        'word': vocab_word,
                        'matched_text': vocab_word,
                        'match_type': 'direct',
                        'text_segment': segment_text,
                        'start_time': segment_start,
                        'end_time': segment_end,
                        'duration': segment_end - segment_start,
                        'confidence': len(vocab_word),
                        'position_in_text': start_pos
                    })
                    matched_positions.append((start_pos, end_pos))
        
        # 2. TÃ¬m tá»« Ä‘á»“ng nghÄ©a vÃ  suy ra tá»« vá»±ng gá»‘c
        for synonym, original_words in reverse_synonym_dict.items():
            synonym_lower = synonym.lower().strip()
            
            pattern = r'\b' + re.escape(synonym_lower) + r'\b'
            matches = list(re.finditer(pattern, text_lower))
            
            for match in matches:
                start_pos = match.start()
                end_pos = match.end()
                
                position_taken = any(
                    start_pos < existing_end and end_pos > existing_start
                    for existing_start, existing_end in matched_positions
                )
                
                if not position_taken and is_valid_match(synonym, segment_text):
                    # ThÃªm táº¥t cáº£ tá»« vá»±ng gá»‘c cÃ³ tá»« Ä‘á»“ng nghÄ©a nÃ y
                    for original_word in original_words:
                        found_words.append({
                            'word': original_word,
                            'matched_text': synonym,
                            'match_type': 'synonym',
                            'text_segment': segment_text,
                            'start_time': segment_start,
                            'end_time': segment_end,
                            'duration': segment_end - segment_start,
                            'confidence': len(synonym),
                            'position_in_text': start_pos
                        })
                    matched_positions.append((start_pos, end_pos))
    
    # Loáº¡i bá» trÃ¹ng láº·p vÃ  sáº¯p xáº¿p theo Ä‘á»™ tin cáº­y
    unique_words = []
    seen = set()
    for word_info in found_words:
        key = (word_info['word'], round(word_info['start_time'], 1))
        if key not in seen:
            seen.add(key)
            unique_words.append(word_info)
    
    # Sáº¯p xáº¿p theo thá»i gian, sau Ä‘Ã³ theo vá»‹ trÃ­ trong cÃ¢u
    unique_words.sort(key=lambda x: (x['start_time'], x['position_in_text']))
    
    return unique_words

def format_time(seconds: float) -> str:
    """
    Chuyá»ƒn Ä‘á»•i giÃ¢y thÃ nh Ä‘á»‹nh dáº¡ng mm:ss
    """
    minutes = int(seconds // 60)
    seconds = int(seconds % 60)
    return f"{minutes:02d}:{seconds:02d}"

def highlight_words_in_sentence(text: str, words: List[str]) -> str:
    """
    TÃ´ sÃ¡ng cÃ¡c tá»« vá»±ng trong cÃ¢u
    """
    highlighted_text = text
    # Sáº¯p xáº¿p tá»« theo Ä‘á»™ dÃ i giáº£m dáº§n Ä‘á»ƒ trÃ¡nh conflict
    words_sorted = sorted(words, key=len, reverse=True)
    
    for word in words_sorted:
        pattern = r'\b' + re.escape(word.lower()) + r'\b'
        highlighted_text = re.sub(
            pattern, 
            f"**{word}**", 
            highlighted_text, 
            flags=re.IGNORECASE
        )
    
    return highlighted_text

def display_vocabulary_results(found_vocabulary: List[Dict], total_vocabulary: int):
    """
    Hiá»ƒn thá»‹ káº¿t quáº£ tÃ¬m kiáº¿m tá»« vá»±ng - tá»«ng tá»« riÃªng biá»‡t theo Ä‘Ãºng thá»© tá»± vá»›i há»— trá»£ tá»« Ä‘á»“ng nghÄ©a
    """
    print("\n" + "="*80)
    print("ğŸ¯ Tá»ª Vá»°NG Tá»ª LABEL.CSV XUáº¤T HIá»†N TRONG VIDEO")
    print("="*80)
    
    if not found_vocabulary:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y tá»« vá»±ng nÃ o tá»« danh sÃ¡ch label trong video")
        return
    
    # Äáº¿m sá»‘ tá»« vá»±ng unique (khÃ´ng tÃ­nh trÃ¹ng láº·p)
    unique_words = set(word_info['word'] for word_info in found_vocabulary)
    direct_matches = [w for w in found_vocabulary if w['match_type'] == 'direct']
    synonym_matches = [w for w in found_vocabulary if w['match_type'] == 'synonym']
    
    print(f"ğŸ“Š TÃ¬m tháº¥y {len(unique_words)} tá»« vá»±ng unique trong tá»•ng sá»‘ {total_vocabulary} tá»« vá»±ng")
    print(f"ğŸ“ˆ Tá»· lá»‡: {len(unique_words)/total_vocabulary*100:.1f}%")
    print(f"ğŸ¯ Trá»±c tiáº¿p: {len(direct_matches)} | ğŸ”„ Qua Ä‘á»“ng nghÄ©a: {len(synonym_matches)}")
    print("\nğŸ“ CHI TIáº¾T CÃC Tá»ª Vá»°NG TÃŒM THáº¤Y (theo thá»© tá»± xuáº¥t hiá»‡n):")
    print("-"*80)
    
    # Sáº¯p xáº¿p táº¥t cáº£ tá»« vá»±ng theo thá»i gian vÃ  vá»‹ trÃ­ trong cÃ¢u
    found_vocabulary.sort(key=lambda x: (x['start_time'], x['position_in_text']))
    
    for i, word_info in enumerate(found_vocabulary, 1):
        start_time = format_time(word_info['start_time'])
        end_time = format_time(word_info['end_time'])
        
        # TÃ´ sÃ¡ng tá»« Ä‘Æ°á»£c match trong ngá»¯ cáº£nh
        highlighted_text = highlight_words_in_sentence(word_info['text_segment'], [word_info['matched_text']])
        
        # Icon vÃ  mÃ u sáº¯c theo loáº¡i match
        match_icon = "ğŸ¯" if word_info['match_type'] == 'direct' else "ğŸ”„"
        
        print(f"{i:2d}. {match_icon} ğŸ• {start_time}-{end_time}")
        print(f"    ğŸ“Œ Tá»« vá»±ng: '{word_info['word']}'")
        
        if word_info['match_type'] == 'synonym':
            print(f"    ğŸ”„ TÃ¬m qua tá»« Ä‘á»“ng nghÄ©a: '{word_info['matched_text']}'")
        
        print(f"    ğŸ’¬ Ngá»¯ cáº£nh: \"{highlighted_text}\"")
        print(f"    ğŸ“ Vá»‹ trÃ­ trong cÃ¢u: kÃ½ tá»± thá»© {word_info['position_in_text'] + 1}")
        print(f"    â±ï¸  Thá»i lÆ°á»£ng: {word_info['duration']:.1f}s")
        print()

# Táº£i model Whisper
print("ğŸ¤– Äang táº£i model Whisper...")
model = whisper.load_model("small")

# Transcribe video vá»›i timestamps
print("ğŸ¬ Äang xá»­ lÃ½ video...")
result = model.transcribe("test.mp4", language="vi", word_timestamps=True, verbose=False)

# Hiá»ƒn thá»‹ text Ä‘áº§y Ä‘á»§
print("ğŸ“œ VÄƒn báº£n Ä‘áº§y Ä‘á»§ tá»« video:")
print(result["text"])

# Táº£i danh sÃ¡ch tá»« vá»±ng tá»« label.csv
print("\nğŸ” Äang táº£i danh sÃ¡ch tá»« vá»±ng tá»« label.csv...")
vocabulary_list, synonym_dict, reverse_synonym_dict = load_vocabulary_from_csv("Dataset/Texts/label.csv")

if vocabulary_list:
    # TÃ¬m tá»« vá»±ng trong text
    print("ğŸ” Äang tÃ¬m kiáº¿m tá»« vá»±ng trong text video...")
    found_vocabulary = find_vocabulary_in_text(result, vocabulary_list, synonym_dict, reverse_synonym_dict)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    display_vocabulary_results(found_vocabulary, len(vocabulary_list))

print("\nâœ… HoÃ n thÃ nh!")
